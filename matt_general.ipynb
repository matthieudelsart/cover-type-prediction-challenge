{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test-full.csv\")\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "# pour avoir cover type au début\n",
    "df_train = df_train[[df_train.columns[-1]] + list(df_train.columns[0:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15120, 56), (581012, 55))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type31  \\\n",
       "0            221             232            148  ...            0   \n",
       "1            220             235            151  ...            0   \n",
       "2            234             238            135  ...            0   \n",
       "3            238             238            122  ...            0   \n",
       "4            220             234            150  ...            0   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0            0  \n",
       "1            0            0            0            0  \n",
       "2            0            0            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2160\n",
       "2    2160\n",
       "3    2160\n",
       "4    2160\n",
       "5    2160\n",
       "6    2160\n",
       "7    2160\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separate features and target \n",
    "X_train = df_train.drop('Cover_Type', axis=1)\n",
    "y_train = df_train['Cover_Type']\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Creating a Test dataset\n",
    "X_test = df_test\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "predictions_df = pd.DataFrame({'Cover_Type': y_pred})\n",
    "\n",
    "# Having it fit the desired format\n",
    "Id = [i for i in range (1, 581013)]\n",
    "predictions_df['Id'] = Id\n",
    "# predictions_df.to_csv('test_predictions.csv', index=False) # peut-être plus simple de directement mettre index = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    236112\n",
       "1    216326\n",
       "3     38178\n",
       "7     31667\n",
       "5     28425\n",
       "6     26278\n",
       "4      4026\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Si on met que la df en input\n",
    "def classif(df_train=df_train, clf=RandomForestClassifier(n_estimators=150, random_state=42)):\n",
    "    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "\n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        X_train, y_train, test_size = 0.2\n",
    "    )\n",
    "\n",
    "    # Initialize and train a Random Forest classifier\n",
    "    clf.fit(data_train, target_train)\n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred = clf.predict(data_test)\n",
    "    \n",
    "    return target_test, y_pred\n",
    "\n",
    "# Si test & train déjà définis\n",
    "def RF_classif_train_test(data_train, target_train, data_test, target_test):\n",
    "\n",
    "    # Initialize and train a Random Forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(data_train, target_train)\n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred = clf.predict(data_test)\n",
    "    \n",
    "    return target_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8882275132275133"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = classif()\n",
    "accuracy_score(y_true, y_pred) # bien meilleur score que sur Kags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.83      0.83       415\n",
      "           2       0.84      0.72      0.77       416\n",
      "           3       0.89      0.87      0.88       441\n",
      "           4       0.94      0.98      0.96       429\n",
      "           5       0.91      0.95      0.93       464\n",
      "           6       0.85      0.87      0.86       416\n",
      "           7       0.95      0.98      0.97       443\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.89      0.89      0.88      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# On prédit moins bien 1 et 2, ce qui est un problème pcq représentent une immense majorité du dataset final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over/undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut essayer d'undersampler wilderness area 4 \n",
    "# pcq à ce stade il semblerait que a été tiré uniformément dans les wilderness areas\n",
    "\n",
    "# ou alors oversampler tous les autres pour aboutir à des proportions similaires à celles d'origine\n",
    "\n",
    "# Ou alors oversampler directement des classes (ex 1 et 2 mais peut être problématique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working directly on the Cover Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.406381\n",
       "1    0.372326\n",
       "3    0.065709\n",
       "7    0.054503\n",
       "5    0.048923\n",
       "6    0.045228\n",
       "4    0.006929\n",
       "Name: Cover_Type, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "predictions_df[\"Cover_Type\"].value_counts() / len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.142857\n",
       "2    0.142857\n",
       "3    0.142857\n",
       "4    0.142857\n",
       "5    0.142857\n",
       "6    0.142857\n",
       "7    0.142857\n",
       "Name: Cover_Type, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Cover_Type\"].value_counts() / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OVERSAMPLING CLASS 2 AND 1\n",
    "\n",
    "ovs_strat = {1: 15_000, 2: 15_000}\n",
    "\n",
    "# Separating train and test\n",
    "X = df_train.drop('Cover_Type', axis=1)\n",
    "y = df_train['Cover_Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "# Define the over-sampler\n",
    "adasyn = ADASYN(sampling_strategy=ovs_strat)\n",
    "\n",
    "# Oversampling\n",
    "X_train_synth, y_train_synth = adasyn.fit_resample(X_train, y_train)\n",
    "X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.391288\n",
       "1    0.386949\n",
       "5    0.044699\n",
       "3    0.044415\n",
       "7    0.044311\n",
       "6    0.044182\n",
       "4    0.044156\n",
       "Name: Cover_Type, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_synth.value_counts() / len(y_train_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.81      0.79       408\n",
      "           2       0.72      0.76      0.74       404\n",
      "           3       0.89      0.81      0.85       440\n",
      "           4       0.94      0.99      0.96       450\n",
      "           5       0.94      0.88      0.91       429\n",
      "           6       0.86      0.88      0.87       449\n",
      "           7       0.97      0.94      0.96       444\n",
      "\n",
      "    accuracy                           0.87      3024\n",
      "   macro avg       0.87      0.87      0.87      3024\n",
      "weighted avg       0.87      0.87      0.87      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = RF_classif_train_test(X_train_synth, y_train_synth, X_test, y_test)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.81      0.81       464\n",
      "           2       0.79      0.75      0.77       421\n",
      "           3       0.89      0.83      0.86       425\n",
      "           4       0.93      0.98      0.96       430\n",
      "           5       0.90      0.95      0.93       399\n",
      "           6       0.88      0.89      0.89       424\n",
      "           7       0.96      0.97      0.96       461\n",
      "\n",
      "    accuracy                           0.88      3024\n",
      "   macro avg       0.88      0.88      0.88      3024\n",
      "weighted avg       0.88      0.88      0.88      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Par rapport à avant, améliore le recall (moins de faux négatifs) mais diminue la précision (plus de faux positifs)\n",
    "\n",
    "y_true, y_pred = classif(df_train)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 16: invalid start byte\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "from utils import clean_predictor\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=150)\n",
    "clf.fit(X_train_synth, y_train_synth)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = clf.predict(df_test)\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "predictions_df = clean_predictor(y_pred)\n",
    "\n",
    "# Having it fit the desired format\n",
    "predictions_df.to_csv('test_predictions.csv', index=False) # peut-être plus simple de directement mettre index = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on atteint 0.82 => Amélioration légère\n",
    "\n",
    "# Essayer de le faire de manière plus méthodique, en augmentant encore plus et notamment le WA1,\n",
    "# et en tunant : on dirait que en fonction du fit du ADASYN on a des résultats assez différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    253208\n",
       "1    218537\n",
       "3     35807\n",
       "7     26433\n",
       "6     23675\n",
       "5     19219\n",
       "4      4133\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remarque que on a sensiblement plus de classe 2 prédite ici que à la base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans + oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from utils import clean_predictor\n",
    "\n",
    "\n",
    "### 1. OVERSAMPLING CLASS 2 AND 1\n",
    "ovs_strat = {1: 30_000, 2: 30_000}\n",
    "\n",
    "# Separating train \n",
    "X_train = df_train.drop(columns=['Cover_Type'], axis=1)\n",
    "y_train = df_train['Cover_Type']\n",
    "\n",
    "# Oversampling\n",
    "adasyn = ADASYN(sampling_strategy=ovs_strat)\n",
    "X_train_synth, y_train_synth = adasyn.fit_resample(X_train, y_train)\n",
    "X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)\n",
    "\n",
    "### 2. KMEANS\n",
    "df_train_ns = df_train.iloc[:,:16]\n",
    "df_test_ns = df_test.iloc[:,:15]\n",
    "\n",
    "km_test = KMeans(n_clusters=3, n_init=10, init=\"k-means++\")\n",
    "km_test.fit_predict(df_test_ns)\n",
    "df_test[\"kmean_cluster\"] = km_test.labels_\n",
    "X_train_synth[\"kmean_cluster\"] = km_test.predict(X_train_synth.iloc[:,:15])\n",
    "\n",
    "### 3. GENERATING\n",
    "cat_col = [\"kmean_cluster\"]\n",
    "cols = X_train_synth.drop(columns=['kmean_cluster']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_col),\n",
    "        (\"others\", \"passthrough\", cols),\n",
    "    ])\n",
    "clf = RandomForestClassifier(n_estimators=150)\n",
    "pipe = make_pipeline(preprocessor, clf)\n",
    "\n",
    "pipe.fit(X_train_synth, y_train_synth)\n",
    "y_pred = pipe.predict(df_test)\n",
    "predictions_df = clean_predictor(y_pred)\n",
    "\n",
    "# Having it fit the desired format\n",
    "# predictions_df.to_csv('test_predictions.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a solid cross validation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idée : appliquer la \"importance weighted cross validation\" du paper.\n",
    "\n",
    "$$\\hat{R}^{(n)}_{kIWCV} = \\frac{1}{k}\\sum_{j=1}^{k} \\frac{1}{|T_j|} \\sum_{(x_i, y_i) \\in T_j} \\frac{p_{test}(x_i)}{p_{train}(x_i)} \\ell(x_i, y_i, \\hat{y_i})$$\n",
    "\n",
    "Question : comment estimer $\\frac{p_{test}(x_i)}{p_{train}(x_i)}$ pour tout $x_i$ du train set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : est-ce que a samplé de manière uniforme sur les classes ? Si oui, on peut juste reweighter sur les proportions des classes. Comment on peut savoir ? On peut nous aussi ressampler au hasard pour avoir des classes uniformes et voir si semble correspondre. \n",
    "\n",
    "Note ici notre loss est la l1 loss = 1 - accuracy donc on peut échanger la loss avec l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trying to get the same data the train from the test\n",
    "class_size = 2160\n",
    "df_copy = pd.DataFrame()\n",
    "\n",
    "for label in range(1,8):\n",
    "    class_data = df_train[df_train['Cover_Type'] == label]\n",
    "    sampled_data = class_data.sample(n=class_size, replace=False, random_state=1000)\n",
    "    df_copy = pd.concat([df_copy, sampled_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "axs[0].hist([df_train[\"Id\"], df_copy[\"Id\"]], bins=100)\n",
    "axs[0].set_title(f'With 100 bins - Perfect match')\n",
    "axs[1].hist([df_train[\"Id\"], df_copy[\"Id\"]], bins=range(0, 600_000, 1000))\n",
    "axs[1].set_title(f'With 1000 bins - slight glitch in first indexes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspond globalement.\n",
    "\n",
    "On peut donc faire $\\frac{p_{test}(x_i)}{p_{train}(x_i)} = \\frac{p_{train}(y_i|x_i) p_{test}(y_i) p_{test}(x_i|y_i)}{p_{test}(y_i|x_i) p_{train}(y_i) p_{train}(x_i|y_i)}$\n",
    "\n",
    "Puis on annule $\\frac{p_{train}(y_i|x_i)}{p_{test}(y_i|x_i)}$ par assumption (label shift) et $\\frac{p_{train}(x_i|y_i)}{p_{test}(x_i|y_i)}$ par ce qu'on vient de voir (au sein d'une classe donnée, les X ont la même distribution)\n",
    "\n",
    "Il reste $\\frac{p_{test}(x_i)}{p_{train}(x_i)} = \\frac{p_{test}(y_i)}{p_{train}(y_i)}$, que l'on peut estimer directement avec les proportions de chaque classe dans le train et indirectement avec les proportions prédites dans le train (c'est une approximation mais ça fera l'affaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = (predictions_df[\"Cover_Type\"].value_counts() / len(predictions_df) / df_train[\"Cover_Type\"].value_counts() * len(df_train)).round(2)\n",
    "coeffs = np.array([2.63, 3.06, 0.43, 0.05, 0.24, 0.27, 0.32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV(df_train=df_train, \n",
    "         predictor=RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs):\n",
    "    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "        \n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        predictor.fit(data_train, target_train)\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7910823889207997,\n",
       " array([0.80953825, 0.72115609, 0.85978142, 0.98255647, 0.95580071,\n",
       "        0.88924534, 0.97947262]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining IWCV and oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV_oversample(df_train=df_train, \n",
    "         predictor=RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs,\n",
    "         verbose=False) :\n",
    "    \n",
    "    ovs_strat = {1: 30_000, 2: 30_000}\n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "\n",
    "    # Define the oversampler\n",
    "    adasyn = ADASYN(sampling_strategy=ovs_strat) ## Random state = 4 ou 1 sont les meilleurs so far à 0.8297 en CV (mais fixer seed aussi en cross_val...)\n",
    "\n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        if verbose:\n",
    "            print(f\"Current fold: {i}\")\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        \n",
    "        # Oversampling\n",
    "        X_train_synth, y_train_synth = adasyn.fit_resample(data_train, target_train)\n",
    "        X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)\n",
    "        \n",
    "        predictor.fit(X_train_synth, y_train_synth)\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling + kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting pipe\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def pipe_setter(n_clusters=3, clf=RandomForestClassifier(n_estimators=100, random_state=42)):\n",
    "    # Initializing kmeans\n",
    "    km_test = KMeans(n_clusters=n_clusters, n_init=10, init=\"k-means++\")\n",
    "    km_test.fit_predict(df_test.loc[:, \"Id\":\"Wilderness_Area4\"])\n",
    "\n",
    "    # Setting pipe\n",
    "    def _enocode_kmeans(X, kmeans=km_test):\n",
    "        X = X.copy()\n",
    "        X[\"kmean_cluster\"] = kmeans.predict(X)\n",
    "        return X\n",
    "    km_encoder = FunctionTransformer(_enocode_kmeans)\n",
    "\n",
    "    cat_col = [\"kmean_cluster\"]\n",
    "    cols = df_train.drop(columns=['Cover_Type', 'Wilderness_Area_Synth']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_col),\n",
    "            (\"others\", \"passthrough\", cols),\n",
    "        ])\n",
    "    \n",
    "    return make_pipeline(km_encoder, preprocessor, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV_ovs_km(df_train=df_train, \n",
    "         predictor=pipe_setter(), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs,\n",
    "         ovs_strat={1: 30_000, 2: 30_000}):\n",
    "    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "\n",
    "    # Define the oversampler\n",
    "    adasyn = ADASYN(sampling_strategy=ovs_strat) \n",
    "\n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        \n",
    "        # Oversampling\n",
    "        X_train_synth, y_train_synth = adasyn.fit_resample(data_train, target_train)\n",
    "        X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)\n",
    "        \n",
    "        predictor.fit(X_train_synth, y_train_synth)\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### très bizarre parce que varie énormément => excellents résultats ou bofs alors que mêmes paramètres\n",
    "# Faire un truc long en 20 - cross val et 3 fois par clusters sur des clusters allant de 3 à 7\n",
    "### So far on dirait que n_clusters = 7 donne le meilleur résultat mais tuner à la fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dico_km =  \n",
    "# 3 (0.8345399423561863, array([0.84882253, 0.79977842, 0.85926981, 0.9786671 , 0.88242925,\n",
    "#        0.86635208, 0.9336357 ]))\n",
    "# 4 (0.8382094548710572, array([0.85103149, 0.8038529 , 0.87349019, 0.97339922, 0.88498326,\n",
    "#        0.86922649, 0.93411541]))\n",
    "# 5 (0.8259548777699849, array([0.83459958, 0.79100115, 0.86031783, 0.98022758, 0.87694589,\n",
    "#        0.87492816, 0.94199221]))\n",
    "# 6 (0.8256605234316455, array([0.83774458, 0.7857139 , 0.87296434, 0.97455323, 0.89697963,\n",
    "#        0.85820505, 0.94403361]))\n",
    "# 7 (0.8406299332597281, array([0.85340261, 0.8082526 , 0.8536078 , 0.97417891, 0.88834775,\n",
    "#        0.87670995, 0.94322887]))\n",
    "# 8 (0.8343907127838309, array([0.8422739 , 0.80129691, 0.867198  , 0.98046184, 0.89575921,\n",
    "#        0.86753523, 0.9481118 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IWCV_ovs_km()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels algos utiliser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.80      0.81       451\n",
      "           2       0.81      0.73      0.77       449\n",
      "           3       0.90      0.88      0.89       420\n",
      "           4       0.96      0.98      0.97       464\n",
      "           5       0.89      0.96      0.93       416\n",
      "           6       0.88      0.91      0.89       407\n",
      "           7       0.96      0.98      0.97       417\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.89      0.89      0.89      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    X_train, y_train, test_size = 0.2\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "target_train = le.fit_transform(target_train)\n",
    "model = XGBClassifier()\n",
    "model.fit(data_train, target_train)\n",
    "y_pred = model.predict(data_test)\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(target_test, y_pred)) # Globalement pareil que le RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.73      0.57       424\n",
      "           2       0.25      0.12      0.17       408\n",
      "           3       0.58      0.37      0.45       446\n",
      "           4       0.51      0.93      0.66       428\n",
      "           5       0.62      0.58      0.60       452\n",
      "           6       0.54      0.35      0.42       439\n",
      "           7       0.80      0.73      0.76       427\n",
      "\n",
      "    accuracy                           0.54      3024\n",
      "   macro avg       0.54      0.54      0.52      3024\n",
      "weighted avg       0.54      0.54      0.52      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "y_true, y_pred = classif(clf=AdaBoostClassifier(algorithm='SAMME'))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       451\n",
      "           2       0.73      0.63      0.68       434\n",
      "           3       0.78      0.81      0.80       415\n",
      "           4       0.94      0.95      0.94       443\n",
      "           5       0.82      0.89      0.85       414\n",
      "           6       0.80      0.78      0.79       418\n",
      "           7       0.88      0.96      0.92       449\n",
      "\n",
      "    accuracy                           0.82      3024\n",
      "   macro avg       0.82      0.82      0.82      3024\n",
      "weighted avg       0.82      0.82      0.82      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=GradientBoostingClassifier())\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.68      0.70       454\n",
      "           2       0.67      0.67      0.67       454\n",
      "           3       0.84      0.79      0.81       448\n",
      "           4       0.93      0.95      0.94       437\n",
      "           5       0.86      0.88      0.87       401\n",
      "           6       0.78      0.81      0.80       405\n",
      "           7       0.91      0.94      0.92       425\n",
      "\n",
      "    accuracy                           0.81      3024\n",
      "   macro avg       0.81      0.82      0.81      3024\n",
      "weighted avg       0.81      0.81      0.81      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=DecisionTreeClassifier())\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.01      0.02       436\n",
      "           2       0.51      0.41      0.46       426\n",
      "           3       0.30      0.42      0.35       426\n",
      "           4       0.54      0.77      0.63       422\n",
      "           5       0.00      0.00      0.00       431\n",
      "           6       0.28      0.41      0.34       438\n",
      "           7       0.37      0.70      0.49       445\n",
      "\n",
      "    accuracy                           0.39      3024\n",
      "   macro avg       0.37      0.39      0.33      3024\n",
      "weighted avg       0.37      0.39      0.32      3024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "y_true, y_pred = classif(clf=SVC(kernel='rbf'))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.67      0.71       409\n",
      "           2       0.74      0.67      0.70       466\n",
      "           3       0.74      0.72      0.73       431\n",
      "           4       0.86      0.92      0.89       431\n",
      "           5       0.85      0.88      0.86       442\n",
      "           6       0.74      0.80      0.77       410\n",
      "           7       0.89      0.94      0.91       435\n",
      "\n",
      "    accuracy                           0.80      3024\n",
      "   macro avg       0.80      0.80      0.80      3024\n",
      "weighted avg       0.80      0.80      0.80      3024\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.60      0.63       407\n",
      "           2       0.67      0.55      0.61       431\n",
      "           3       0.69      0.68      0.68       462\n",
      "           4       0.88      0.90      0.89       440\n",
      "           5       0.80      0.87      0.83       433\n",
      "           6       0.70      0.74      0.72       432\n",
      "           7       0.85      0.94      0.89       419\n",
      "\n",
      "    accuracy                           0.75      3024\n",
      "   macro avg       0.75      0.75      0.75      3024\n",
      "weighted avg       0.75      0.75      0.75      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=KNeighborsClassifier(1))\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "y_true, y_pred = classif(clf=KNeighborsClassifier(5))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.08      0.12       439\n",
      "           2       0.80      0.02      0.04       434\n",
      "           3       0.38      0.01      0.02       450\n",
      "           4       0.91      0.63      0.75       407\n",
      "           5       0.57      0.18      0.27       395\n",
      "           6       0.35      0.66      0.46       464\n",
      "           7       0.26      0.97      0.41       435\n",
      "\n",
      "    accuracy                           0.36      3024\n",
      "   macro avg       0.51      0.36      0.30      3024\n",
      "weighted avg       0.50      0.36      0.29      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=MLPClassifier())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.56      0.55       428\n",
      "           2       0.48      0.37      0.42       469\n",
      "           3       0.61      0.47      0.53       452\n",
      "           4       0.80      0.87      0.83       406\n",
      "           5       0.64      0.70      0.67       454\n",
      "           6       0.52      0.60      0.56       407\n",
      "           7       0.75      0.83      0.79       408\n",
      "\n",
      "    accuracy                           0.62      3024\n",
      "   macro avg       0.62      0.63      0.62      3024\n",
      "weighted avg       0.62      0.62      0.62      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "y_true, y_pred = classif(clf=GaussianNB())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.83      0.82       417\n",
      "           2       0.84      0.75      0.79       469\n",
      "           3       0.87      0.88      0.88       416\n",
      "           4       0.93      0.98      0.96       425\n",
      "           5       0.91      0.93      0.92       437\n",
      "           6       0.87      0.87      0.87       408\n",
      "           7       0.95      0.98      0.97       452\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.88      0.89      0.89      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=ExtraTreesClassifier())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.961071\n",
      "[LightGBM] [Info] Start training from score -1.943021\n",
      "[LightGBM] [Info] Start training from score -1.941867\n",
      "[LightGBM] [Info] Start training from score -1.940715\n",
      "[LightGBM] [Info] Start training from score -1.945332\n",
      "[LightGBM] [Info] Start training from score -1.952296\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.79      0.81       458\n",
      "           2       0.82      0.71      0.76       427\n",
      "           3       0.89      0.88      0.88       425\n",
      "           4       0.95      0.97      0.96       423\n",
      "           5       0.91      0.96      0.94       431\n",
      "           6       0.89      0.92      0.90       443\n",
      "           7       0.91      0.97      0.94       417\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.88      0.89      0.89      3024\n",
      "weighted avg       0.88      0.89      0.88      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=LGBMClassifier())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.946939\n",
      "[LightGBM] [Info] Start training from score -1.939245\n",
      "[LightGBM] [Info] Start training from score -1.945396\n",
      "[LightGBM] [Info] Start training from score -1.950034\n",
      "[LightGBM] [Info] Start training from score -1.946939\n",
      "[LightGBM] [Info] Start training from score -1.940779\n",
      "[LightGBM] [Info] Start training from score -1.952102\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2415\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.947970\n",
      "[LightGBM] [Info] Start training from score -1.946425\n",
      "[LightGBM] [Info] Start training from score -1.949001\n",
      "[LightGBM] [Info] Start training from score -1.935675\n",
      "[LightGBM] [Info] Start training from score -1.941291\n",
      "[LightGBM] [Info] Start training from score -1.952102\n",
      "[LightGBM] [Info] Start training from score -1.949001\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2415\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.944368\n",
      "[LightGBM] [Info] Start training from score -1.950551\n",
      "[LightGBM] [Info] Start training from score -1.945396\n",
      "[LightGBM] [Info] Start training from score -1.953138\n",
      "[LightGBM] [Info] Start training from score -1.948485\n",
      "[LightGBM] [Info] Start training from score -1.931610\n",
      "[LightGBM] [Info] Start training from score -1.947970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2420\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.942828\n",
      "[LightGBM] [Info] Start training from score -1.939245\n",
      "[LightGBM] [Info] Start training from score -1.959375\n",
      "[LightGBM] [Info] Start training from score -1.947970\n",
      "[LightGBM] [Info] Start training from score -1.942316\n",
      "[LightGBM] [Info] Start training from score -1.949517\n",
      "[LightGBM] [Info] Start training from score -1.940268\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2417\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.947455\n",
      "[LightGBM] [Info] Start training from score -1.954175\n",
      "[LightGBM] [Info] Start training from score -1.950034\n",
      "[LightGBM] [Info] Start training from score -1.949517\n",
      "[LightGBM] [Info] Start training from score -1.943855\n",
      "[LightGBM] [Info] Start training from score -1.941291\n",
      "[LightGBM] [Info] Start training from score -1.935166\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2421\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.949517\n",
      "[LightGBM] [Info] Start training from score -1.947970\n",
      "[LightGBM] [Info] Start training from score -1.952620\n",
      "[LightGBM] [Info] Start training from score -1.949517\n",
      "[LightGBM] [Info] Start training from score -1.938734\n",
      "[LightGBM] [Info] Start training from score -1.947970\n",
      "[LightGBM] [Info] Start training from score -1.935166\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.948485\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.943855\n",
      "[LightGBM] [Info] Start training from score -1.938224\n",
      "[LightGBM] [Info] Start training from score -1.948485\n",
      "[LightGBM] [Info] Start training from score -1.946939\n",
      "[LightGBM] [Info] Start training from score -1.949517\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2417\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.944368\n",
      "[LightGBM] [Info] Start training from score -1.950551\n",
      "[LightGBM] [Info] Start training from score -1.943855\n",
      "[LightGBM] [Info] Start training from score -1.945396\n",
      "[LightGBM] [Info] Start training from score -1.942828\n",
      "[LightGBM] [Info] Start training from score -1.947970\n",
      "[LightGBM] [Info] Start training from score -1.946425\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2420\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.951585\n",
      "[LightGBM] [Info] Start training from score -1.951067\n",
      "[LightGBM] [Info] Start training from score -1.938224\n",
      "[LightGBM] [Info] Start training from score -1.945396\n",
      "[LightGBM] [Info] Start training from score -1.941803\n",
      "[LightGBM] [Info] Start training from score -1.948485\n",
      "[LightGBM] [Info] Start training from score -1.944882\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 13608, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.944882\n",
      "[LightGBM] [Info] Start training from score -1.955213\n",
      "[LightGBM] [Info] Start training from score -1.950034\n",
      "[LightGBM] [Info] Start training from score -1.935675\n",
      "[LightGBM] [Info] Start training from score -1.952620\n",
      "[LightGBM] [Info] Start training from score -1.936693\n",
      "[LightGBM] [Info] Start training from score -1.946425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8051053933747129,\n",
       " array([0.81217726, 0.7444687 , 0.88809278, 0.97956911, 0.96056728,\n",
       "        0.91257205, 0.98077622]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWCV(predictor=LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2456\n",
      "[LightGBM] [Info] Number of data points in the train set: 69823, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.835278\n",
      "[LightGBM] [Info] Start training from score -0.851388\n",
      "[LightGBM] [Info] Start training from score -3.568438\n",
      "[LightGBM] [Info] Start training from score -3.581216\n",
      "[LightGBM] [Info] Start training from score -3.585339\n",
      "[LightGBM] [Info] Start training from score -3.583275\n",
      "[LightGBM] [Info] Start training from score -3.580187\n",
      "Current fold: 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2458\n",
      "[LightGBM] [Info] Number of data points in the train set: 70101, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.834607\n",
      "[LightGBM] [Info] Start training from score -0.850475\n",
      "[LightGBM] [Info] Start training from score -3.582621\n",
      "[LightGBM] [Info] Start training from score -3.585189\n",
      "[LightGBM] [Info] Start training from score -3.581083\n",
      "[LightGBM] [Info] Start training from score -3.594492\n",
      "[LightGBM] [Info] Start training from score -3.579547\n",
      "Current fold: 2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2460\n",
      "[LightGBM] [Info] Number of data points in the train set: 69090, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -0.846521\n",
      "[LightGBM] [Info] Start training from score -0.842413\n",
      "[LightGBM] [Info] Start training from score -3.571692\n",
      "[LightGBM] [Info] Start training from score -3.566556\n",
      "[LightGBM] [Info] Start training from score -3.574270\n",
      "[LightGBM] [Info] Start training from score -3.572207\n",
      "[LightGBM] [Info] Start training from score -3.577890\n",
      "Current fold: 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2457\n",
      "[LightGBM] [Info] Number of data points in the train set: 69045, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.846477\n",
      "[LightGBM] [Info] Start training from score -0.843578\n",
      "[LightGBM] [Info] Start training from score -3.568982\n",
      "[LightGBM] [Info] Start training from score -3.566416\n",
      "[LightGBM] [Info] Start training from score -3.570011\n",
      "[LightGBM] [Info] Start training from score -3.571555\n",
      "[LightGBM] [Info] Start training from score -3.568469\n",
      "Current fold: 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2458\n",
      "[LightGBM] [Info] Number of data points in the train set: 69409, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.842225\n",
      "[LightGBM] [Info] Start training from score -0.845810\n",
      "[LightGBM] [Info] Start training from score -3.568093\n",
      "[LightGBM] [Info] Start training from score -3.576813\n",
      "[LightGBM] [Info] Start training from score -3.566562\n",
      "[LightGBM] [Info] Start training from score -3.575783\n",
      "[LightGBM] [Info] Start training from score -3.589255\n",
      "Current fold: 5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2456\n",
      "[LightGBM] [Info] Number of data points in the train set: 69175, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -0.846638\n",
      "[LightGBM] [Info] Start training from score -0.842366\n",
      "[LightGBM] [Info] Start training from score -3.581194\n",
      "[LightGBM] [Info] Start training from score -3.578602\n",
      "[LightGBM] [Info] Start training from score -3.573436\n",
      "[LightGBM] [Info] Start training from score -3.569836\n",
      "[LightGBM] [Info] Start training from score -3.558606\n",
      "Current fold: 6\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2456\n",
      "[LightGBM] [Info] Number of data points in the train set: 69384, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.848711\n",
      "[LightGBM] [Info] Start training from score -0.838892\n",
      "[LightGBM] [Info] Start training from score -3.577484\n",
      "[LightGBM] [Info] Start training from score -3.571314\n",
      "[LightGBM] [Info] Start training from score -3.572853\n",
      "[LightGBM] [Info] Start training from score -3.586290\n",
      "[LightGBM] [Info] Start training from score -3.575423\n",
      "Current fold: 7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2449\n",
      "[LightGBM] [Info] Number of data points in the train set: 69669, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -0.836510\n",
      "[LightGBM] [Info] Start training from score -0.850960\n",
      "[LightGBM] [Info] Start training from score -3.572854\n",
      "[LightGBM] [Info] Start training from score -3.572343\n",
      "[LightGBM] [Info] Start training from score -3.577466\n",
      "[LightGBM] [Info] Start training from score -3.582099\n",
      "[LightGBM] [Info] Start training from score -3.581067\n",
      "Current fold: 8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2457\n",
      "[LightGBM] [Info] Number of data points in the train set: 69532, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -0.845870\n",
      "[LightGBM] [Info] Start training from score -0.841790\n",
      "[LightGBM] [Info] Start training from score -3.578069\n",
      "[LightGBM] [Info] Start training from score -3.574984\n",
      "[LightGBM] [Info] Start training from score -3.578584\n",
      "[LightGBM] [Info] Start training from score -3.570374\n",
      "[LightGBM] [Info] Start training from score -3.580131\n",
      "Current fold: 9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2457\n",
      "[LightGBM] [Info] Number of data points in the train set: 69346, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.849511\n",
      "[LightGBM] [Info] Start training from score -0.838811\n",
      "[LightGBM] [Info] Start training from score -3.577968\n",
      "[LightGBM] [Info] Start training from score -3.579001\n",
      "[LightGBM] [Info] Start training from score -3.560567\n",
      "[LightGBM] [Info] Start training from score -3.577452\n",
      "[LightGBM] [Info] Start training from score -3.577452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8270647235083031,\n",
       " array([0.83081706, 0.79668071, 0.84769642, 0.97189811, 0.88295062,\n",
       "        0.88517751, 0.94547122]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWCV_oversample(predictor=LGBMClassifier(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(estimators=[\n",
    "                        ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),\n",
    "                        ('xtr', ExtraTreesClassifier(random_state=42)),\n",
    "                        ('lgbm', LGBMClassifier(random_state=42)),\n",
    "                        ('KNN5', KNeighborsClassifier(5)), # Essayer 1\n",
    "                    ], \n",
    "                   final_estimator=RandomForestClassifier(random_state=42), \n",
    "                   cv=5,\n",
    "                   n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.80      0.82       436\n",
      "           2       0.80      0.80      0.80       418\n",
      "           3       0.86      0.90      0.88       418\n",
      "           4       0.97      0.97      0.97       451\n",
      "           5       0.94      0.94      0.94       436\n",
      "           6       0.89      0.87      0.88       408\n",
      "           7       0.95      0.96      0.96       457\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.89      0.89      0.89      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = classif(clf=stack)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m IWCV_oversample(predictor\u001b[38;5;241m=\u001b[39mstack)\n",
      "Cell \u001b[1;32mIn[29], line 28\u001b[0m, in \u001b[0;36mIWCV_oversample\u001b[1;34m(df_train, predictor, k_valid, coeffs)\u001b[0m\n\u001b[0;32m     25\u001b[0m X_train_synth, y_train_synth \u001b[38;5;241m=\u001b[39m adasyn\u001b[38;5;241m.\u001b[39mfit_resample(data_train, target_train)\n\u001b[0;32m     26\u001b[0m X_train_synth \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_train_synth, columns\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 28\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(X_train_synth, y_train_synth)\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(data_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:663\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    662\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y_encoded, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:253\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[0;32m    250\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    251\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     )\n\u001b[1;32m--> 253\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    254\u001b[0m         delayed(cross_val_predict)(\n\u001b[0;32m    255\u001b[0m             clone(est),\n\u001b[0;32m    256\u001b[0m             X,\n\u001b[0;32m    257\u001b[0m             y,\n\u001b[0;32m    258\u001b[0m             cv\u001b[38;5;241m=\u001b[39mdeepcopy(cv),\n\u001b[0;32m    259\u001b[0m             method\u001b[38;5;241m=\u001b[39mmeth,\n\u001b[0;32m    260\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    261\u001b[0m             params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    262\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    263\u001b[0m         )\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    271\u001b[0m     meth\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IWCV_oversample(predictor=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe_setter(n_clusters=7, clf=stack)\n",
    "IWCV_ovs_km(pipe, ovs_strat={ovs_strat={1: 15_000, 2: 15_000}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using weights in LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_types = [f\"Soil_Type{i}\" for i in range(1, 41)]\n",
    "wilderness_areas = [f\"Wilderness_Area{i}\" for i in range(1,5)]\n",
    "df_test[\"Wilderness_Area_Synth\"] = df_test[wilderness_areas] @ range(1,5)\n",
    "df_train[\"Wilderness_Area_Synth\"] = df_train[wilderness_areas] @ range(1,5)\n",
    "df_test[\"Soil_Type_Synth\"] = df_test[soil_types] @ range(1,41)\n",
    "df_train[\"Soil_Type_Synth\"] = df_train[soil_types] @ range(1,41)\n",
    "df_train = df_train.drop(columns=wilderness_areas + soil_types)\n",
    "df_test = df_test.drop(columns=wilderness_areas + soil_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Cover_Type', axis=1)\n",
    "y_train = df_train['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8019087603957136,\n",
       " array([0.81588716, 0.73611261, 0.88221707, 0.97433567, 0.96167315,\n",
       "        0.89894112, 0.97964913]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import IWCV\n",
    "\n",
    "lgbm = LGBMClassifier(n_jobs=-1, verbose=0, random_state=0)\n",
    "IWCV(df_train=df_train, predictor=lgbm, k_valid=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {\n",
    "    1: 0.4,\n",
    "    2: 0.4,\n",
    "    3: 0.04,\n",
    "    4: 0.04,\n",
    "    5: 0.04,\n",
    "    6: 0.04,\n",
    "    7: 0.04\n",
    "}\n",
    "\n",
    "clf = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=7,\n",
    "    class_weight=class_weights,\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5,\n",
       "               class_weight={1: 0.4, 2: 0.4, 3: 0.04, 4: 0.04, 5: 0.04, 6: 0.04,\n",
       "                             7: 0.04},\n",
       "               feature_fraction=0.9, learning_rate=0.05, num_class=7,\n",
       "               objective=&#x27;multiclass&#x27;, verbose=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5,\n",
       "               class_weight={1: 0.4, 2: 0.4, 3: 0.04, 4: 0.04, 5: 0.04, 6: 0.04,\n",
       "                             7: 0.04},\n",
       "               feature_fraction=0.9, learning_rate=0.05, num_class=7,\n",
       "               objective=&#x27;multiclass&#x27;, verbose=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5,\n",
       "               class_weight={1: 0.4, 2: 0.4, 3: 0.04, 4: 0.04, 5: 0.04, 6: 0.04,\n",
       "                             7: 0.04},\n",
       "               feature_fraction=0.9, learning_rate=0.05, num_class=7,\n",
       "               objective='multiclass', verbose=0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, categorical_feature=['Wilderness_Area_Synth', 'Soil_Type_Synth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    261293\n",
       "1    222086\n",
       "3     33279\n",
       "7     23752\n",
       "6     21237\n",
       "5     15395\n",
       "4      3970\n",
       "dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV(df_train=df_train, \n",
    "         predictor=RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    df_train: training data\n",
    "    predictor: classifier (can be a sklearn pipeline)\n",
    "    k_valid: number of cross-validations desired\n",
    "            \n",
    "    Outputs:\n",
    "    1. IWCV - unbiased estimate of test score if assumptions are correct\n",
    "    2. clean_accuracies - array of estimated accuracy per class\n",
    "    \"\"\"    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "        \n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        predictor.fit(data_train, target_train, categorical_feature=['Wilderness_Area_Synth', 'Soil_Type_Synth'])\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong type(str) or unknown name(Wilderness_Area_Synth) in categorical_feature",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m IWCV(df_train\u001b[38;5;241m=\u001b[39mdf_train, predictor\u001b[38;5;241m=\u001b[39mclf, k_valid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[1;32mIn[172], line 28\u001b[0m, in \u001b[0;36mIWCV\u001b[1;34m(df_train, predictor, k_valid, coeffs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_valid):\n\u001b[0;32m     25\u001b[0m     data_train, data_test, target_train, target_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     26\u001b[0m         X_train, y_train, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m k_valid\n\u001b[0;32m     27\u001b[0m     )\n\u001b[1;32m---> 28\u001b[0m     predictor\u001b[38;5;241m.\u001b[39mfit(data_train, target_train, categorical_feature\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWilderness_Area_Synth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoil_Type_Synth\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(data_test)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1187\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1185\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1187\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1188\u001b[0m     X,\n\u001b[0;32m   1189\u001b[0m     _y,\n\u001b[0;32m   1190\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1191\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[0;32m   1192\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m   1193\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m   1194\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[0;32m   1195\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[0;32m   1196\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[0;32m   1197\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m   1198\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   1199\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[0;32m   1200\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1201\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model\n\u001b[0;32m   1202\u001b[0m )\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    886\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    887\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[0;32m    888\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[0;32m    889\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m    890\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m    891\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m    893\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m    894\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m    895\u001b[0m )\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    257\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:3433\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   3427\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   3428\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3429\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   3430\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3431\u001b[0m     )\n\u001b[0;32m   3432\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 3433\u001b[0m train_set\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[0;32m   3434\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   3435\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:2462\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2455\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2456\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   2457\u001b[0m                 data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   2458\u001b[0m                 used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2459\u001b[0m             )\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2461\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2462\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2463\u001b[0m                     weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[0;32m   2464\u001b[0m                     init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score, predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   2465\u001b[0m                     feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature,\n\u001b[0;32m   2466\u001b[0m                     params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition)\n\u001b[0;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:2048\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2046\u001b[0m         categorical_indices\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2048\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong type(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(name)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) or unknown name(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in categorical_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m categorical_indices:\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat_alias \u001b[38;5;129;01min\u001b[39;00m _ConfigAliases\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: Wrong type(str) or unknown name(Wilderness_Area_Synth) in categorical_feature"
     ]
    }
   ],
   "source": [
    "IWCV(df_train=df_train, predictor=clf, k_valid=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>Wilderness_Area_Synth</th>\n",
       "      <th>Soil_Type_Synth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>242642</td>\n",
       "      <td>2881</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>210</td>\n",
       "      <td>54</td>\n",
       "      <td>1020</td>\n",
       "      <td>250</td>\n",
       "      <td>221</td>\n",
       "      <td>88</td>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>309891</td>\n",
       "      <td>3005</td>\n",
       "      <td>351</td>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "      <td>-16</td>\n",
       "      <td>1371</td>\n",
       "      <td>194</td>\n",
       "      <td>215</td>\n",
       "      <td>159</td>\n",
       "      <td>842</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>287847</td>\n",
       "      <td>3226</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>618</td>\n",
       "      <td>2</td>\n",
       "      <td>1092</td>\n",
       "      <td>232</td>\n",
       "      <td>210</td>\n",
       "      <td>107</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>516307</td>\n",
       "      <td>3298</td>\n",
       "      <td>317</td>\n",
       "      <td>8</td>\n",
       "      <td>661</td>\n",
       "      <td>60</td>\n",
       "      <td>752</td>\n",
       "      <td>198</td>\n",
       "      <td>233</td>\n",
       "      <td>174</td>\n",
       "      <td>1248</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>124860</td>\n",
       "      <td>3080</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>3705</td>\n",
       "      <td>219</td>\n",
       "      <td>227</td>\n",
       "      <td>144</td>\n",
       "      <td>2673</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15115</th>\n",
       "      <td>7</td>\n",
       "      <td>475155</td>\n",
       "      <td>3328</td>\n",
       "      <td>321</td>\n",
       "      <td>13</td>\n",
       "      <td>323</td>\n",
       "      <td>12</td>\n",
       "      <td>5109</td>\n",
       "      <td>186</td>\n",
       "      <td>227</td>\n",
       "      <td>180</td>\n",
       "      <td>3151</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15116</th>\n",
       "      <td>7</td>\n",
       "      <td>514378</td>\n",
       "      <td>3455</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>841</td>\n",
       "      <td>92</td>\n",
       "      <td>939</td>\n",
       "      <td>220</td>\n",
       "      <td>229</td>\n",
       "      <td>146</td>\n",
       "      <td>362</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>7</td>\n",
       "      <td>368425</td>\n",
       "      <td>3279</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>404</td>\n",
       "      <td>113</td>\n",
       "      <td>1513</td>\n",
       "      <td>240</td>\n",
       "      <td>218</td>\n",
       "      <td>105</td>\n",
       "      <td>1503</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15118</th>\n",
       "      <td>7</td>\n",
       "      <td>537844</td>\n",
       "      <td>3589</td>\n",
       "      <td>357</td>\n",
       "      <td>9</td>\n",
       "      <td>418</td>\n",
       "      <td>52</td>\n",
       "      <td>1868</td>\n",
       "      <td>205</td>\n",
       "      <td>223</td>\n",
       "      <td>155</td>\n",
       "      <td>1657</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15119</th>\n",
       "      <td>7</td>\n",
       "      <td>463634</td>\n",
       "      <td>3385</td>\n",
       "      <td>345</td>\n",
       "      <td>15</td>\n",
       "      <td>350</td>\n",
       "      <td>76</td>\n",
       "      <td>3625</td>\n",
       "      <td>190</td>\n",
       "      <td>216</td>\n",
       "      <td>164</td>\n",
       "      <td>3327</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cover_Type      Id  Elevation  Aspect  Slope  \\\n",
       "0               1  242642       2881     130     22   \n",
       "1               1  309891       3005     351     14   \n",
       "2               1  287847       3226      63     14   \n",
       "3               1  516307       3298     317      8   \n",
       "4               1  124860       3080      35      6   \n",
       "...           ...     ...        ...     ...    ...   \n",
       "15115           7  475155       3328     321     13   \n",
       "15116           7  514378       3455      37      5   \n",
       "15117           7  368425       3279      90     14   \n",
       "15118           7  537844       3589     357      9   \n",
       "15119           7  463634       3385     345     15   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "0                                   210                              54   \n",
       "1                                   242                             -16   \n",
       "2                                   618                               2   \n",
       "3                                   661                              60   \n",
       "4                                   175                              26   \n",
       "...                                 ...                             ...   \n",
       "15115                               323                              12   \n",
       "15116                               841                              92   \n",
       "15117                               404                             113   \n",
       "15118                               418                              52   \n",
       "15119                               350                              76   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "0                                 1020            250             221   \n",
       "1                                 1371            194             215   \n",
       "2                                 1092            232             210   \n",
       "3                                  752            198             233   \n",
       "4                                 3705            219             227   \n",
       "...                                ...            ...             ...   \n",
       "15115                             5109            186             227   \n",
       "15116                              939            220             229   \n",
       "15117                             1513            240             218   \n",
       "15118                             1868            205             223   \n",
       "15119                             3625            190             216   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points  \\\n",
       "0                 88                                 342   \n",
       "1                159                                 842   \n",
       "2                107                                2018   \n",
       "3                174                                1248   \n",
       "4                144                                2673   \n",
       "...              ...                                 ...   \n",
       "15115            180                                3151   \n",
       "15116            146                                 362   \n",
       "15117            105                                1503   \n",
       "15118            155                                1657   \n",
       "15119            164                                3327   \n",
       "\n",
       "       Wilderness_Area_Synth  Soil_Type_Synth  \n",
       "0                          1               30  \n",
       "1                          3               24  \n",
       "2                          1               29  \n",
       "3                          2               23  \n",
       "4                          1               24  \n",
       "...                      ...              ...  \n",
       "15115                      3               38  \n",
       "15116                      2               40  \n",
       "15117                      1               29  \n",
       "15118                      2               40  \n",
       "15119                      3               40  \n",
       "\n",
       "[15120 rows x 14 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call fit before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mSeries(model\u001b[38;5;241m.\u001b[39mpredict(df_test)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1223\u001b[0m, in \u001b[0;36mLGBMClassifier.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   1221\u001b[0m ):\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(\n\u001b[0;32m   1224\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1225\u001b[0m         raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   1226\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1227\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1228\u001b[0m         pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   1229\u001b[0m         pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   1230\u001b[0m         validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1231\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1232\u001b[0m     )\n\u001b[0;32m   1233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mor\u001b[39;00m raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib:\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1253\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1243\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   1251\u001b[0m ):\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1253\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1254\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1255\u001b[0m         raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   1256\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1257\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1258\u001b[0m         pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   1259\u001b[0m         pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   1260\u001b[0m         validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1262\u001b[0m     )\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[0;32m   1264\u001b[0m         _log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1265\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1266\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:932\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[1;32m--> 932\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator not fitted, call fit before exploiting the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m    934\u001b[0m     X \u001b[38;5;241m=\u001b[39m _LGBMCheckArray(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Estimator not fitted, call fit before exploiting the model."
     ]
    }
   ],
   "source": [
    "pd.Series(model.predict(df_test).round(0)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
