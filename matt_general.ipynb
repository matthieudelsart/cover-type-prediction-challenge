{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test-full.csv\")\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "# pour avoir cover type au début\n",
    "df_train = df_train[[df_train.columns[-1]] + list(df_train.columns[0:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15120, 56), (581012, 55))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type31  \\\n",
       "0            221             232            148  ...            0   \n",
       "1            220             235            151  ...            0   \n",
       "2            234             238            135  ...            0   \n",
       "3            238             238            122  ...            0   \n",
       "4            220             234            150  ...            0   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0            0  \n",
       "1            0            0            0            0  \n",
       "2            0            0            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2160\n",
       "2    2160\n",
       "3    2160\n",
       "4    2160\n",
       "5    2160\n",
       "6    2160\n",
       "7    2160\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separate features and target \n",
    "X_train = df_train.drop('Cover_Type', axis=1)\n",
    "y_train = df_train['Cover_Type']\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Creating a Test dataset\n",
    "X_test = df_test\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "predictions_df = pd.DataFrame({'Cover_Type': y_pred})\n",
    "\n",
    "# Having it fit the desired format\n",
    "Id = [i for i in range (1, 581013)]\n",
    "predictions_df['Id'] = Id\n",
    "# predictions_df.to_csv('test_predictions.csv', index=False) # peut-être plus simple de directement mettre index = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    236112\n",
       "1    216326\n",
       "3     38178\n",
       "7     31667\n",
       "5     28425\n",
       "6     26278\n",
       "4      4026\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Si on met que la df en input\n",
    "def classif(df_train=df_train, clf=RandomForestClassifier(n_estimators=150, random_state=42)):\n",
    "    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "\n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        X_train, y_train, test_size = 0.2\n",
    "    )\n",
    "\n",
    "    # Initialize and train a Random Forest classifier\n",
    "    clf.fit(data_train, target_train)\n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred = clf.predict(data_test)\n",
    "    \n",
    "    return target_test, y_pred\n",
    "\n",
    "# Si test & train déjà définis\n",
    "def RF_classif_train_test(data_train, target_train, data_test, target_test):\n",
    "\n",
    "    # Initialize and train a Random Forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(data_train, target_train)\n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred = clf.predict(data_test)\n",
    "    \n",
    "    return target_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8882275132275133"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = classif()\n",
    "accuracy_score(y_true, y_pred) # bien meilleur score que sur Kags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.83      0.83       415\n",
      "           2       0.84      0.72      0.77       416\n",
      "           3       0.89      0.87      0.88       441\n",
      "           4       0.94      0.98      0.96       429\n",
      "           5       0.91      0.95      0.93       464\n",
      "           6       0.85      0.87      0.86       416\n",
      "           7       0.95      0.98      0.97       443\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.89      0.89      0.88      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# On prédit moins bien 1 et 2, ce qui est un problème pcq représentent une immense majorité du dataset final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over/undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut essayer d'undersampler wilderness area 4 \n",
    "# pcq à ce stade il semblerait que a été tiré uniformément dans les wilderness areas\n",
    "\n",
    "# ou alors oversampler tous les autres pour aboutir à des proportions similaires à celles d'origine\n",
    "\n",
    "# Ou alors oversampler directement des classes (ex 1 et 2 mais peut être problématique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working directly on the Cover Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.406381\n",
       "1    0.372326\n",
       "3    0.065709\n",
       "7    0.054503\n",
       "5    0.048923\n",
       "6    0.045228\n",
       "4    0.006929\n",
       "Name: Cover_Type, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "predictions_df[\"Cover_Type\"].value_counts() / len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.142857\n",
       "2    0.142857\n",
       "3    0.142857\n",
       "4    0.142857\n",
       "5    0.142857\n",
       "6    0.142857\n",
       "7    0.142857\n",
       "Name: Cover_Type, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Cover_Type\"].value_counts() / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OVERSAMPLING CLASS 2 AND 1\n",
    "\n",
    "ovs_strat = {1: 15_000, 2: 15_000}\n",
    "\n",
    "# Separating train and test\n",
    "X = df_train.drop('Cover_Type', axis=1)\n",
    "y = df_train['Cover_Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "# Define the over-sampler\n",
    "adasyn = ADASYN(sampling_strategy=ovs_strat)\n",
    "\n",
    "# Oversampling\n",
    "X_train_synth, y_train_synth = adasyn.fit_resample(X_train, y_train)\n",
    "X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.391288\n",
       "1    0.386949\n",
       "5    0.044699\n",
       "3    0.044415\n",
       "7    0.044311\n",
       "6    0.044182\n",
       "4    0.044156\n",
       "Name: Cover_Type, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_synth.value_counts() / len(y_train_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.81      0.79       408\n",
      "           2       0.72      0.76      0.74       404\n",
      "           3       0.89      0.81      0.85       440\n",
      "           4       0.94      0.99      0.96       450\n",
      "           5       0.94      0.88      0.91       429\n",
      "           6       0.86      0.88      0.87       449\n",
      "           7       0.97      0.94      0.96       444\n",
      "\n",
      "    accuracy                           0.87      3024\n",
      "   macro avg       0.87      0.87      0.87      3024\n",
      "weighted avg       0.87      0.87      0.87      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = RF_classif_train_test(X_train_synth, y_train_synth, X_test, y_test)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.81      0.81       464\n",
      "           2       0.79      0.75      0.77       421\n",
      "           3       0.89      0.83      0.86       425\n",
      "           4       0.93      0.98      0.96       430\n",
      "           5       0.90      0.95      0.93       399\n",
      "           6       0.88      0.89      0.89       424\n",
      "           7       0.96      0.97      0.96       461\n",
      "\n",
      "    accuracy                           0.88      3024\n",
      "   macro avg       0.88      0.88      0.88      3024\n",
      "weighted avg       0.88      0.88      0.88      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Par rapport à avant, améliore le recall (moins de faux négatifs) mais diminue la précision (plus de faux positifs)\n",
    "\n",
    "y_true, y_pred = classif(df_train)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 16: invalid start byte\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "from utils import clean_predictor\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=150)\n",
    "clf.fit(X_train_synth, y_train_synth)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = clf.predict(df_test)\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "predictions_df = clean_predictor(y_pred)\n",
    "\n",
    "# Having it fit the desired format\n",
    "predictions_df.to_csv('test_predictions.csv', index=False) # peut-être plus simple de directement mettre index = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on atteint 0.82 => Amélioration légère\n",
    "\n",
    "# Essayer de le faire de manière plus méthodique, en augmentant encore plus et notamment le WA1,\n",
    "# et en tunant : on dirait que en fonction du fit du ADASYN on a des résultats assez différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    253208\n",
       "1    218537\n",
       "3     35807\n",
       "7     26433\n",
       "6     23675\n",
       "5     19219\n",
       "4      4133\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remarque que on a sensiblement plus de classe 2 prédite ici que à la base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans + oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from utils import clean_predictor\n",
    "\n",
    "\n",
    "### 1. OVERSAMPLING CLASS 2 AND 1\n",
    "ovs_strat = {1: 30_000, 2: 30_000}\n",
    "\n",
    "# Separating train \n",
    "X_train = df_train.drop(columns=['Cover_Type'], axis=1)\n",
    "y_train = df_train['Cover_Type']\n",
    "\n",
    "# Oversampling\n",
    "adasyn = ADASYN(sampling_strategy=ovs_strat)\n",
    "X_train_synth, y_train_synth = adasyn.fit_resample(X_train, y_train)\n",
    "X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)\n",
    "\n",
    "### 2. KMEANS\n",
    "df_train_ns = df_train.iloc[:,:16]\n",
    "df_test_ns = df_test.iloc[:,:15]\n",
    "\n",
    "km_test = KMeans(n_clusters=3, n_init=10, init=\"k-means++\")\n",
    "km_test.fit_predict(df_test_ns)\n",
    "df_test[\"kmean_cluster\"] = km_test.labels_\n",
    "X_train_synth[\"kmean_cluster\"] = km_test.predict(X_train_synth.iloc[:,:15])\n",
    "\n",
    "### 3. GENERATING\n",
    "cat_col = [\"kmean_cluster\"]\n",
    "cols = X_train_synth.drop(columns=['kmean_cluster']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_col),\n",
    "        (\"others\", \"passthrough\", cols),\n",
    "    ])\n",
    "clf = RandomForestClassifier(n_estimators=150)\n",
    "pipe = make_pipeline(preprocessor, clf)\n",
    "\n",
    "pipe.fit(X_train_synth, y_train_synth)\n",
    "y_pred = pipe.predict(df_test)\n",
    "predictions_df = clean_predictor(y_pred)\n",
    "\n",
    "# Having it fit the desired format\n",
    "# predictions_df.to_csv('test_predictions.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a solid cross validation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idée : appliquer la \"importance weighted cross validation\" du paper.\n",
    "\n",
    "$$\\hat{R}^{(n)}_{kIWCV} = \\frac{1}{k}\\sum_{j=1}^{k} \\frac{1}{|T_j|} \\sum_{(x_i, y_i) \\in T_j} \\frac{p_{test}(x_i)}{p_{train}(x_i)} \\ell(x_i, y_i, \\hat{y_i})$$\n",
    "\n",
    "Question : comment estimer $\\frac{p_{test}(x_i)}{p_{train}(x_i)}$ pour tout $x_i$ du train set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : est-ce que a samplé de manière uniforme sur les classes ? Si oui, on peut juste reweighter sur les proportions des classes. Comment on peut savoir ? On peut nous aussi ressampler au hasard pour avoir des classes uniformes et voir si semble correspondre. \n",
    "\n",
    "Note ici notre loss est la l1 loss = 1 - accuracy donc on peut échanger la loss avec l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trying to get the same data the train from the test\n",
    "class_size = 2160\n",
    "df_copy = pd.DataFrame()\n",
    "\n",
    "for label in range(1,8):\n",
    "    class_data = df_train[df_train['Cover_Type'] == label]\n",
    "    sampled_data = class_data.sample(n=class_size, replace=False, random_state=1000)\n",
    "    df_copy = pd.concat([df_copy, sampled_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "axs[0].hist([df_train[\"Id\"], df_copy[\"Id\"]], bins=100)\n",
    "axs[0].set_title(f'With 100 bins - Perfect match')\n",
    "axs[1].hist([df_train[\"Id\"], df_copy[\"Id\"]], bins=range(0, 600_000, 1000))\n",
    "axs[1].set_title(f'With 1000 bins - slight glitch in first indexes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspond globalement.\n",
    "\n",
    "On peut donc faire $\\frac{p_{test}(x_i)}{p_{train}(x_i)} = \\frac{p_{train}(y_i|x_i) p_{test}(y_i) p_{test}(x_i|y_i)}{p_{test}(y_i|x_i) p_{train}(y_i) p_{train}(x_i|y_i)}$\n",
    "\n",
    "Puis on annule $\\frac{p_{train}(y_i|x_i)}{p_{test}(y_i|x_i)}$ par assumption (label shift) et $\\frac{p_{train}(x_i|y_i)}{p_{test}(x_i|y_i)}$ par ce qu'on vient de voir (au sein d'une classe donnée, les X ont la même distribution)\n",
    "\n",
    "Il reste $\\frac{p_{test}(x_i)}{p_{train}(x_i)} = \\frac{p_{test}(y_i)}{p_{train}(y_i)}$, que l'on peut estimer directement avec les proportions de chaque classe dans le train et indirectement avec les proportions prédites dans le train (c'est une approximation mais ça fera l'affaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = (predictions_df[\"Cover_Type\"].value_counts() / len(predictions_df) / df_train[\"Cover_Type\"].value_counts() * len(df_train)).round(2)\n",
    "coeffs = np.array([2.63, 3.06, 0.43, 0.05, 0.24, 0.27, 0.32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV(df_train=df_train, \n",
    "         predictor=RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs):\n",
    "    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "        \n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        predictor.fit(data_train, target_train)\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7910823889207997,\n",
       " array([0.80953825, 0.72115609, 0.85978142, 0.98255647, 0.95580071,\n",
       "        0.88924534, 0.97947262]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IWCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining IWCV and oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV_oversample(df_train=df_train, \n",
    "         predictor=RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs) :\n",
    "    \n",
    "    ovs_strat = {1: 30_000, 2: 30_000}\n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "\n",
    "    # Define the oversampler\n",
    "    adasyn = ADASYN(sampling_strategy=ovs_strat) ## Random state = 4 ou 1 sont les meilleurs so far à 0.8297 en CV (mais fixer seed aussi en cross_val...)\n",
    "\n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        \n",
    "        # Oversampling\n",
    "        X_train_synth, y_train_synth = adasyn.fit_resample(data_train, target_train)\n",
    "        X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)\n",
    "        \n",
    "        predictor.fit(X_train_synth, y_train_synth)\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling + kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting pipe\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def pipe_setter(n_clusters=3, clf=RandomForestClassifier(n_estimators=100, random_state=42)):\n",
    "    # Initializing kmeans\n",
    "    km_test = KMeans(n_clusters=n_clusters, n_init=10, init=\"k-means++\")\n",
    "    km_test.fit_predict(df_test.loc[:, \"Id\":\"Wilderness_Area4\"])\n",
    "\n",
    "    # Setting pipe\n",
    "    def _enocode_kmeans(X, kmeans=km_test):\n",
    "        X = X.copy()\n",
    "        X[\"kmean_cluster\"] = kmeans.predict(X)\n",
    "        return X\n",
    "    km_encoder = FunctionTransformer(_enocode_kmeans)\n",
    "\n",
    "    cat_col = [\"kmean_cluster\"]\n",
    "    cols = df_train.drop(columns=['Cover_Type', 'Wilderness_Area_Synth']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_col),\n",
    "            (\"others\", \"passthrough\", cols),\n",
    "        ])\n",
    "    \n",
    "    return make_pipeline(km_encoder, preprocessor, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IWCV_ovs_km(df_train=df_train, \n",
    "         predictor=pipe_setter(), \n",
    "         k_valid=10,\n",
    "         coeffs=coeffs,\n",
    "         ovs_strat={1: 30_000, 2: 30_000}):\n",
    "    \n",
    "    if \"Wilderness_Area_Synth\" in df_train.columns:\n",
    "        df_train = df_train.drop(columns=\"Wilderness_Area_Synth\")\n",
    "\n",
    "    # Define the oversampler\n",
    "    adasyn = ADASYN(sampling_strategy=ovs_strat) \n",
    "\n",
    "    # Separate features and target \n",
    "    X_train = df_train.drop('Cover_Type', axis=1)\n",
    "    y_train = df_train['Cover_Type']\n",
    "    \n",
    "    class_accuracies = np.zeros((k_valid, 7))\n",
    "    \n",
    "    for i in range(k_valid):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            X_train, y_train, test_size = 1 / k_valid\n",
    "        )\n",
    "        \n",
    "        # Oversampling\n",
    "        X_train_synth, y_train_synth = adasyn.fit_resample(data_train, target_train)\n",
    "        X_train_synth = pd.DataFrame(X_train_synth, columns=X_train.columns)\n",
    "        \n",
    "        predictor.fit(X_train_synth, y_train_synth)\n",
    "        y_pred = predictor.predict(data_test)\n",
    "\n",
    "        for label in range(1,8):\n",
    "            class_accuracies[i, label - 1] = accuracy_score(target_test[target_test == label], \n",
    "                                                        y_pred[target_test == label])\n",
    "        IMCV = np.mean(class_accuracies @ coeffs) / np.sum(coeffs)\n",
    "        \n",
    "    return IMCV, class_accuracies.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### très bizarre parce que varie énormément => excellents résultats ou bofs alors que mêmes paramètres\n",
    "# Faire un truc long en 20 - cross val et 3 fois par clusters sur des clusters allant de 3 à 7\n",
    "### So far on dirait que n_clusters = 7 donne le meilleur résultat mais tuner à la fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dico_km =  \n",
    "# 3 (0.8345399423561863, array([0.84882253, 0.79977842, 0.85926981, 0.9786671 , 0.88242925,\n",
    "#        0.86635208, 0.9336357 ]))\n",
    "# 4 (0.8382094548710572, array([0.85103149, 0.8038529 , 0.87349019, 0.97339922, 0.88498326,\n",
    "#        0.86922649, 0.93411541]))\n",
    "# 5 (0.8259548777699849, array([0.83459958, 0.79100115, 0.86031783, 0.98022758, 0.87694589,\n",
    "#        0.87492816, 0.94199221]))\n",
    "# 6 (0.8256605234316455, array([0.83774458, 0.7857139 , 0.87296434, 0.97455323, 0.89697963,\n",
    "#        0.85820505, 0.94403361]))\n",
    "# 7 (0.8406299332597281, array([0.85340261, 0.8082526 , 0.8536078 , 0.97417891, 0.88834775,\n",
    "#        0.87670995, 0.94322887]))\n",
    "# 8 (0.8343907127838309, array([0.8422739 , 0.80129691, 0.867198  , 0.98046184, 0.89575921,\n",
    "#        0.86753523, 0.9481118 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IWCV_ovs_km()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels algos utiliser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.80      0.81       451\n",
      "           2       0.81      0.73      0.77       449\n",
      "           3       0.90      0.88      0.89       420\n",
      "           4       0.96      0.98      0.97       464\n",
      "           5       0.89      0.96      0.93       416\n",
      "           6       0.88      0.91      0.89       407\n",
      "           7       0.96      0.98      0.97       417\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.89      0.89      0.89      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    X_train, y_train, test_size = 0.2\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "target_train = le.fit_transform(target_train)\n",
    "model = XGBClassifier()\n",
    "model.fit(data_train, target_train)\n",
    "y_pred = model.predict(data_test)\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(target_test, y_pred)) # Globalement pareil que le RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.73      0.57       424\n",
      "           2       0.25      0.12      0.17       408\n",
      "           3       0.58      0.37      0.45       446\n",
      "           4       0.51      0.93      0.66       428\n",
      "           5       0.62      0.58      0.60       452\n",
      "           6       0.54      0.35      0.42       439\n",
      "           7       0.80      0.73      0.76       427\n",
      "\n",
      "    accuracy                           0.54      3024\n",
      "   macro avg       0.54      0.54      0.52      3024\n",
      "weighted avg       0.54      0.54      0.52      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "y_true, y_pred = classif(clf=AdaBoostClassifier(algorithm='SAMME'))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       451\n",
      "           2       0.73      0.63      0.68       434\n",
      "           3       0.78      0.81      0.80       415\n",
      "           4       0.94      0.95      0.94       443\n",
      "           5       0.82      0.89      0.85       414\n",
      "           6       0.80      0.78      0.79       418\n",
      "           7       0.88      0.96      0.92       449\n",
      "\n",
      "    accuracy                           0.82      3024\n",
      "   macro avg       0.82      0.82      0.82      3024\n",
      "weighted avg       0.82      0.82      0.82      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=GradientBoostingClassifier())\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.68      0.70       454\n",
      "           2       0.67      0.67      0.67       454\n",
      "           3       0.84      0.79      0.81       448\n",
      "           4       0.93      0.95      0.94       437\n",
      "           5       0.86      0.88      0.87       401\n",
      "           6       0.78      0.81      0.80       405\n",
      "           7       0.91      0.94      0.92       425\n",
      "\n",
      "    accuracy                           0.81      3024\n",
      "   macro avg       0.81      0.82      0.81      3024\n",
      "weighted avg       0.81      0.81      0.81      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=DecisionTreeClassifier())\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.01      0.02       436\n",
      "           2       0.51      0.41      0.46       426\n",
      "           3       0.30      0.42      0.35       426\n",
      "           4       0.54      0.77      0.63       422\n",
      "           5       0.00      0.00      0.00       431\n",
      "           6       0.28      0.41      0.34       438\n",
      "           7       0.37      0.70      0.49       445\n",
      "\n",
      "    accuracy                           0.39      3024\n",
      "   macro avg       0.37      0.39      0.33      3024\n",
      "weighted avg       0.37      0.39      0.32      3024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "y_true, y_pred = classif(clf=SVC(kernel='rbf'))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.67      0.71       409\n",
      "           2       0.74      0.67      0.70       466\n",
      "           3       0.74      0.72      0.73       431\n",
      "           4       0.86      0.92      0.89       431\n",
      "           5       0.85      0.88      0.86       442\n",
      "           6       0.74      0.80      0.77       410\n",
      "           7       0.89      0.94      0.91       435\n",
      "\n",
      "    accuracy                           0.80      3024\n",
      "   macro avg       0.80      0.80      0.80      3024\n",
      "weighted avg       0.80      0.80      0.80      3024\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.60      0.63       407\n",
      "           2       0.67      0.55      0.61       431\n",
      "           3       0.69      0.68      0.68       462\n",
      "           4       0.88      0.90      0.89       440\n",
      "           5       0.80      0.87      0.83       433\n",
      "           6       0.70      0.74      0.72       432\n",
      "           7       0.85      0.94      0.89       419\n",
      "\n",
      "    accuracy                           0.75      3024\n",
      "   macro avg       0.75      0.75      0.75      3024\n",
      "weighted avg       0.75      0.75      0.75      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=KNeighborsClassifier(1))\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "y_true, y_pred = classif(clf=KNeighborsClassifier(5))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.08      0.12       439\n",
      "           2       0.80      0.02      0.04       434\n",
      "           3       0.38      0.01      0.02       450\n",
      "           4       0.91      0.63      0.75       407\n",
      "           5       0.57      0.18      0.27       395\n",
      "           6       0.35      0.66      0.46       464\n",
      "           7       0.26      0.97      0.41       435\n",
      "\n",
      "    accuracy                           0.36      3024\n",
      "   macro avg       0.51      0.36      0.30      3024\n",
      "weighted avg       0.50      0.36      0.29      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=MLPClassifier())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.56      0.55       428\n",
      "           2       0.48      0.37      0.42       469\n",
      "           3       0.61      0.47      0.53       452\n",
      "           4       0.80      0.87      0.83       406\n",
      "           5       0.64      0.70      0.67       454\n",
      "           6       0.52      0.60      0.56       407\n",
      "           7       0.75      0.83      0.79       408\n",
      "\n",
      "    accuracy                           0.62      3024\n",
      "   macro avg       0.62      0.63      0.62      3024\n",
      "weighted avg       0.62      0.62      0.62      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "y_true, y_pred = classif(clf=GaussianNB())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.83      0.82       417\n",
      "           2       0.84      0.75      0.79       469\n",
      "           3       0.87      0.88      0.88       416\n",
      "           4       0.93      0.98      0.96       425\n",
      "           5       0.91      0.93      0.92       437\n",
      "           6       0.87      0.87      0.87       408\n",
      "           7       0.95      0.98      0.97       452\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.88      0.89      0.89      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=ExtraTreesClassifier())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 12096, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.961071\n",
      "[LightGBM] [Info] Start training from score -1.943021\n",
      "[LightGBM] [Info] Start training from score -1.941867\n",
      "[LightGBM] [Info] Start training from score -1.940715\n",
      "[LightGBM] [Info] Start training from score -1.945332\n",
      "[LightGBM] [Info] Start training from score -1.952296\n",
      "[LightGBM] [Info] Start training from score -1.937267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.79      0.81       458\n",
      "           2       0.82      0.71      0.76       427\n",
      "           3       0.89      0.88      0.88       425\n",
      "           4       0.95      0.97      0.96       423\n",
      "           5       0.91      0.96      0.94       431\n",
      "           6       0.89      0.92      0.90       443\n",
      "           7       0.91      0.97      0.94       417\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.88      0.89      0.89      3024\n",
      "weighted avg       0.88      0.89      0.88      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "y_true, y_pred = classif(clf=LGBMClassifier())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(estimators=[\n",
    "                        ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),\n",
    "                        ('xtr', ExtraTreesClassifier(random_state=42)),\n",
    "                        ('lgbm', LGBMClassifier(random_state=42)),\n",
    "                        ('KNN5', KNeighborsClassifier(5)), # Essayer 1\n",
    "                    ], \n",
    "                   final_estimator=RandomForestClassifier(random_state=42), \n",
    "                   cv=5,\n",
    "                   n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.80      0.82       436\n",
      "           2       0.80      0.80      0.80       418\n",
      "           3       0.86      0.90      0.88       418\n",
      "           4       0.97      0.97      0.97       451\n",
      "           5       0.94      0.94      0.94       436\n",
      "           6       0.89      0.87      0.88       408\n",
      "           7       0.95      0.96      0.96       457\n",
      "\n",
      "    accuracy                           0.89      3024\n",
      "   macro avg       0.89      0.89      0.89      3024\n",
      "weighted avg       0.89      0.89      0.89      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = classif(clf=stack)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m IWCV_oversample(predictor\u001b[38;5;241m=\u001b[39mstack)\n",
      "Cell \u001b[1;32mIn[29], line 28\u001b[0m, in \u001b[0;36mIWCV_oversample\u001b[1;34m(df_train, predictor, k_valid, coeffs)\u001b[0m\n\u001b[0;32m     25\u001b[0m X_train_synth, y_train_synth \u001b[38;5;241m=\u001b[39m adasyn\u001b[38;5;241m.\u001b[39mfit_resample(data_train, target_train)\n\u001b[0;32m     26\u001b[0m X_train_synth \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_train_synth, columns\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 28\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(X_train_synth, y_train_synth)\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(data_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:663\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    662\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y_encoded, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:253\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[0;32m    250\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    251\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     )\n\u001b[1;32m--> 253\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    254\u001b[0m         delayed(cross_val_predict)(\n\u001b[0;32m    255\u001b[0m             clone(est),\n\u001b[0;32m    256\u001b[0m             X,\n\u001b[0;32m    257\u001b[0m             y,\n\u001b[0;32m    258\u001b[0m             cv\u001b[38;5;241m=\u001b[39mdeepcopy(cv),\n\u001b[0;32m    259\u001b[0m             method\u001b[38;5;241m=\u001b[39mmeth,\n\u001b[0;32m    260\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    261\u001b[0m             params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    262\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    263\u001b[0m         )\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    271\u001b[0m     meth\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IWCV_oversample(predictor=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe_setter(n_clusters=7, clf=stack)\n",
    "IWCV_ovs_km(pipe, ovs_strat={ovs_strat={1: 15_000, 2: 15_000}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
