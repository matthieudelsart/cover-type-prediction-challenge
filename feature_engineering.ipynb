{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from lightgbm import LGBMClassifier\n",
    "from feature_engineering import *\n",
    "from check_score.scorer import Kaggle_score, get_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_data_train()\n",
    "df_test = get_data_test()\n",
    "\n",
    "X_train = df_train.drop(columns=[\"Cover_Type\"], axis=1)\n",
    "y_train = df_train[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m      3\u001b[0m lgbm \u001b[38;5;241m=\u001b[39m LGBMClassifier(\n\u001b[1;32m      4\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m IWCV(df_train, lgbm, k_valid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m get_model_score(lgbm, df_train)\n",
      "File \u001b[0;32m~/Documents/X-HEC Msc DataScience for Business/X-2023/Cours/Semester 2/MAP541 - Machine Learning 2/ML2_Forest/check_score/scorer.py:30\u001b[0m, in \u001b[0;36mget_model_score\u001b[0;34m(model, df, categorical_feature)\u001b[0m\n\u001b[1;32m     26\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(df_test)\n\u001b[1;32m     28\u001b[0m pred \u001b[38;5;241m=\u001b[39m clean_predictor(y_pred\u001b[38;5;241m=\u001b[39mpred, Id\u001b[38;5;241m=\u001b[39mdf_test\u001b[38;5;241m.\u001b[39mId)\n\u001b[0;32m---> 30\u001b[0m truth \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/ground_truth.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCover_Type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     32\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (pred\u001b[38;5;241m.\u001b[39mCover_Type\u001b[38;5;241m.\u001b[39mto_numpy() \u001b[38;5;241m==\u001b[39m truth)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parquet.py:501\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[1;32m    449\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    455\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m    DataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    504\u001b[0m         path,\n\u001b[1;32m    505\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    509\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parquet.py:52\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     50\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "c_w ={1: 0.4, 2: 0.45, 3: 0.04,4: 0.01, 5: 0.04, 6: 0.04, 7: 0.04},\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=7,\n",
    "    class_weight=c_w,\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    n_estimators=300,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(IWCV(df_train, lgbm, k_valid=10))\n",
    "\n",
    "get_model_score(lgbm, df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "      <th>ST_concat</th>\n",
       "      <th>geological_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242642</td>\n",
       "      <td>2881</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>210</td>\n",
       "      <td>54</td>\n",
       "      <td>1020</td>\n",
       "      <td>250</td>\n",
       "      <td>221</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309891</td>\n",
       "      <td>3005</td>\n",
       "      <td>351</td>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "      <td>-16</td>\n",
       "      <td>1371</td>\n",
       "      <td>194</td>\n",
       "      <td>215</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287847</td>\n",
       "      <td>3226</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>618</td>\n",
       "      <td>2</td>\n",
       "      <td>1092</td>\n",
       "      <td>232</td>\n",
       "      <td>210</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516307</td>\n",
       "      <td>3298</td>\n",
       "      <td>317</td>\n",
       "      <td>8</td>\n",
       "      <td>661</td>\n",
       "      <td>60</td>\n",
       "      <td>752</td>\n",
       "      <td>198</td>\n",
       "      <td>233</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124860</td>\n",
       "      <td>3080</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>3705</td>\n",
       "      <td>219</td>\n",
       "      <td>227</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15115</th>\n",
       "      <td>475155</td>\n",
       "      <td>3328</td>\n",
       "      <td>321</td>\n",
       "      <td>13</td>\n",
       "      <td>323</td>\n",
       "      <td>12</td>\n",
       "      <td>5109</td>\n",
       "      <td>186</td>\n",
       "      <td>227</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15116</th>\n",
       "      <td>514378</td>\n",
       "      <td>3455</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>841</td>\n",
       "      <td>92</td>\n",
       "      <td>939</td>\n",
       "      <td>220</td>\n",
       "      <td>229</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>368425</td>\n",
       "      <td>3279</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>404</td>\n",
       "      <td>113</td>\n",
       "      <td>1513</td>\n",
       "      <td>240</td>\n",
       "      <td>218</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15118</th>\n",
       "      <td>537844</td>\n",
       "      <td>3589</td>\n",
       "      <td>357</td>\n",
       "      <td>9</td>\n",
       "      <td>418</td>\n",
       "      <td>52</td>\n",
       "      <td>1868</td>\n",
       "      <td>205</td>\n",
       "      <td>223</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15119</th>\n",
       "      <td>463634</td>\n",
       "      <td>3385</td>\n",
       "      <td>345</td>\n",
       "      <td>15</td>\n",
       "      <td>350</td>\n",
       "      <td>76</td>\n",
       "      <td>3625</td>\n",
       "      <td>190</td>\n",
       "      <td>216</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15120 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0      242642       2881     130     22                               210   \n",
       "1      309891       3005     351     14                               242   \n",
       "2      287847       3226      63     14                               618   \n",
       "3      516307       3298     317      8                               661   \n",
       "4      124860       3080      35      6                               175   \n",
       "...       ...        ...     ...    ...                               ...   \n",
       "15115  475155       3328     321     13                               323   \n",
       "15116  514378       3455      37      5                               841   \n",
       "15117  368425       3279      90     14                               404   \n",
       "15118  537844       3589     357      9                               418   \n",
       "15119  463634       3385     345     15                               350   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                  54                             1020   \n",
       "1                                 -16                             1371   \n",
       "2                                   2                             1092   \n",
       "3                                  60                              752   \n",
       "4                                  26                             3705   \n",
       "...                               ...                              ...   \n",
       "15115                              12                             5109   \n",
       "15116                              92                              939   \n",
       "15117                             113                             1513   \n",
       "15118                              52                             1868   \n",
       "15119                              76                             3625   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type34  \\\n",
       "0                250             221             88  ...            0   \n",
       "1                194             215            159  ...            0   \n",
       "2                232             210            107  ...            0   \n",
       "3                198             233            174  ...            0   \n",
       "4                219             227            144  ...            0   \n",
       "...              ...             ...            ...  ...          ...   \n",
       "15115            186             227            180  ...            0   \n",
       "15116            220             229            146  ...            0   \n",
       "15117            240             218            105  ...            0   \n",
       "15118            205             223            155  ...            0   \n",
       "15119            190             216            164  ...            0   \n",
       "\n",
       "       Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  \\\n",
       "0                0            0            0            0            0   \n",
       "1                0            0            0            0            0   \n",
       "2                0            0            0            0            0   \n",
       "3                0            0            0            0            0   \n",
       "4                0            0            0            0            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "15115            0            0            0            1            0   \n",
       "15116            0            0            0            0            0   \n",
       "15117            0            0            0            0            0   \n",
       "15118            0            0            0            0            0   \n",
       "15119            0            0            0            0            0   \n",
       "\n",
       "       Soil_Type40  Cover_Type  ST_concat  geological_zone  \n",
       "0                0           1         30                7  \n",
       "1                0           1         24                7  \n",
       "2                0           1         29                7  \n",
       "3                0           1         23                2  \n",
       "4                0           1         24                7  \n",
       "...            ...         ...        ...              ...  \n",
       "15115            0           7         38                7  \n",
       "15116            1           7         40                0  \n",
       "15117            0           7         29                7  \n",
       "15118            1           7         40                0  \n",
       "15119            1           7         40                0  \n",
       "\n",
       "[15120 rows x 58 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    df = concat_Soil_Type(df, new_name='ST_concat', drop_value=True) \n",
    "    df = concat_Wilderness_Area(df, new_name='WA_concat', drop_value=True) \n",
    "    df = group_climatic_zone(df)\n",
    "    df = group_geological_zone(df)\n",
    "    return df\n",
    "\n",
    "df_train_new = preprocess(df_train)\n",
    "cat_col = [ 'ST_concat', 'WA_concat','climatic_zone', 'geological_zone']\n",
    "\n",
    "X_train = df_train_new.drop(columns=[\"Cover_Type\"], axis=1)\n",
    "y_train = df_train_new[\"Cover_Type\"]\n",
    "lgbm.fit(X_train, y_train, categorical_feature=cat_col)\n",
    "pred = lgbm.predict(df_test)\n",
    "\n",
    "pred = clean_predictor(y_pred=pred.Cover_Type, Id=pred.Id)\n",
    "csv_for_submission(pred,\"pred_test\")\n",
    "Kaggle_score('Output/pred_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST = {\n",
    "    1: {\n",
    "        \"ELU\": 2702,\n",
    "        \"family\":\"Cathedral\", \n",
    "        \"complex\": \"Rock outcrop complex\", \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    2: {\n",
    "        \"ELU\": 2703,\n",
    "        \"family\":\"Vanet\",\n",
    "        \"complex\": \"Ratake families complex\", \n",
    "        \"stone\":\"very stony\",\n",
    "        },\n",
    "    3: {\n",
    "        \"ELU\": 2704,\n",
    "        \"family\":\"\",#Haploborolis - \n",
    "        \"complex\":\"Rock outcrop complex\",\n",
    "        \"stone\":\"rubbly\",\n",
    "        },\n",
    "    4: {\n",
    "        \"ELU\": 2705,\n",
    "        \"family\":\"Ratake\", \n",
    "        \"complex\": \"Rock outcrop complex\", \n",
    "        \"stone\":\"rubbly\",\n",
    "        },\n",
    "    5: {\n",
    "        \"ELU\": 2706,\n",
    "        \"family\":\"Vanet\",\n",
    "        \"complex\":\"Rock outcrop complex complex\",\n",
    "        \"stone\":\"rubbly\",\n",
    "        },\n",
    "    6: {\n",
    "        \"ELU\": 2717,\n",
    "        \"family\":\"\",#Vanet - Wetmore families - \n",
    "        \"complex\":\"Rock outcrop complex\", \n",
    "        \"stone\":\"stony\",\n",
    "        },\n",
    "    7: {\n",
    "        \"ELU\": 3501,\n",
    "        \"family\":\"Gothic\",\n",
    "        \"complex\":\"\",\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    8: {\n",
    "        \"ELU\": 3502,\n",
    "        \"family\":\"\",#Supervisor - \n",
    "        \"complex\":\"Limber families complex\",\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    9: {\n",
    "        \"ELU\": 4201,\n",
    "        \"family\":\"Troutville\", \n",
    "        \"stone\":\"very stony\",\n",
    "        },\n",
    "    10: {\n",
    "        \"ELU\": 4703,\n",
    "        \"family\":\"Catamount\", #Bullwark - \n",
    "        \"complex\":\"Rock outcrop complex\", \n",
    "        \"stone\":\"rubbly\",\n",
    "        },\n",
    "    11: {\n",
    "        \"ELU\": 4704,\n",
    "        \"family\":\"Catamount\",# Bullwark - \n",
    "        \"complex\":\"Rock land complex\",\n",
    "        \"stone\":\"rubbly\",\n",
    "        },\n",
    "    12: {\n",
    "        \"ELU\": 4744,\n",
    "        \"family\":\"Legault\",\n",
    "        \"complex\":\"Rock land complex\",\n",
    "        \"stone\":\"stony\",\n",
    "        },\n",
    "    13: {\n",
    "        \"ELU\": 4758,\n",
    "        \"family\":\"Catamount\",# - Rock land - Bullwark family complex,\n",
    "        \"stone\":\"rubbly\",\n",
    "        },\n",
    "    14: {\n",
    "        \"ELU\": 5101,\n",
    "        \"family\":\"\",#Pachic Argiborolis - \n",
    "        \"complex\":\"Aquolis complex\",\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    15: {\n",
    "        \"ELU\": 5151,\n",
    "        \"family\":None,\n",
    "        \"stone\":None,\n",
    "        },\n",
    "    16: {\n",
    "        \"ELU\": 6101,\n",
    "        \"family\":\"\",#Cryaquolis - Cryoborolis complex.\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    17: {\n",
    "        \"ELU\": 6102,\n",
    "        \"family\":\"Gateview\", #- Cryaquolis complex.,\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    18: {\n",
    "        \"ELU\": 6731,\n",
    "        \"family\":\"Rogert\",\n",
    "        \"stone\":\"very stony\",\n",
    "        },\n",
    "    19: {\n",
    "        \"ELU\": 7101,\n",
    "        \"family\":\"\",#Typic Cryaquolis - Borohemists complex.,\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    20: {\n",
    "        \"ELU\": 7102,\n",
    "        \"family\":\"\",#Typic Cryaquepts - Typic Cryaquolls complex.,\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    21: {\n",
    "        \"ELU\": 7103,\n",
    "        \"family\":\"Leighcan\", #Typic Cryaquolls -, till substratum complex.,\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    22: {\n",
    "        \"ELU\": 7201,\n",
    "        \"family\":\"Leighcan\",  #till substratum, \n",
    "        \"stone\":\"extremely bouldery\",\n",
    "        },\n",
    "    23: {\n",
    "        \"ELU\": 7202,\n",
    "        \"family\":\"Leighcan\",  #till substratum - Typic Cryaquolls complex.,\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    24: {\n",
    "        \"ELU\": 7700,\n",
    "        \"family\":\"Leighcan\", \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    25: {\n",
    "        \"ELU\": 7701,\n",
    "        \"family\":\"Leighcan\", #warm, \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    26: {\n",
    "        \"ELU\": 7702,\n",
    "        \"family\":\"Catamount\", #Granile -  complex,\n",
    "        \"stone\":\"very stony\",\n",
    "        },\n",
    "    27: {\n",
    "        \"ELU\": 7709,\n",
    "        \"family\":\"Leighcan\", #warm - \n",
    "         \"complex\":\"Rock outcrop complex\",\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    28: {\n",
    "        \"ELU\": 7710,\n",
    "        \"family\":\"Leighcan\",\n",
    "        \"complex\":\"Rock outcrop complex\", \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    29: {\n",
    "        \"ELU\": 7745,\n",
    "        \"family\":\"Como\",#- Legault families complex, \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    30: {\n",
    "        \"ELU\": 7746,\n",
    "        \"family\":\"Como\", #- Rock land - Legault family complex, \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    31: {\n",
    "        \"ELU\": 7755,\n",
    "        \"family\":\"Catamount\",# Leighcan -  complex, \n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    32: {\n",
    "        \"ELU\": 7756,\n",
    "        \"family\":\"Catamount\", # - Rock outcrop - Leighcan family complex,\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    33: {\n",
    "        \"ELU\": 7757,\n",
    "        \"family\":\"Catamount\", #Leighcan\n",
    "        \"complex\":\"Rock outcrop complex\",\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    34: {\n",
    "        \"ELU\": 7790,\n",
    "        \"family\":\"\",#Cryorthents - \n",
    "        \"complex\":\"Rock land complex\",\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    35: {\n",
    "        \"ELU\": 8703,\n",
    "        \"family\":\"\",#Cryumbrepts - Rock outcrop - Cryaquepts complex.,\n",
    "        \"stone\":\"\",\n",
    "        },\n",
    "    36: {\n",
    "        \"ELU\": 8707,\n",
    "        \"family\":\"Bross\", #- Rock land - Cryumbrepts complex,\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    37: {\n",
    "        \"ELU\": 8708,\n",
    "        \"family\":\"\",#Rock outcrop - Cryumbrepts - Cryorthents complex,\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    38: {\n",
    "        \"ELU\": 8771,\n",
    "        \"family\":\"Moran\", #- Leighcan - Cryaquolls complex,\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    39: {\n",
    "        \"ELU\": 8772,\n",
    "        \"family\":\"Moran\", # - Cryorthents - Leighcan family complex,\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "    40: {\n",
    "        \"ELU\": 8776,\n",
    "        \"family\":\"Moran\", #- Cryorthents - \n",
    "        \"complex\":\"Rock land complex\",\n",
    "        \"stone\":\"extremely stony\",\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = concat_Soil_Type(df, new_name='ST_concat', drop_value=True) \n",
    "    df = concat_Wilderness_Area(df, new_name='WA_concat', drop_value=True) \n",
    "    df = group_climatic_zone(df)\n",
    "    df = group_geological_zone(df)\n",
    "    ELU_new = {k:v['ELU']%100 for k, v in ST.items()}\n",
    "    df['ELU'] = df['ST_concat'].map(ELU_new)\n",
    "    family_new = {k:v['family'] for k, v in ST.items()}\n",
    "    df['family'] = df['ST_concat'].map(family_new)\n",
    "    stone_new = {k:v['stone'] for k, v in ST.items()}\n",
    "    df['stone'] = df['ST_concat'].map(stone_new)\n",
    "    return df\n",
    "\n",
    "df_train1 = preprocess(df_train)\n",
    "enc = OneHotEncoder(categories=['ELU', \"family\", \"stone\"])\n",
    "df_train1 = enc.fit_transform(df_train1)\n",
    "df_test1 = preprocess(df_test)\n",
    "df_test1 = enc.transform(df_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    283301\n",
       "1    211840\n",
       "3     35754\n",
       "7     20510\n",
       "6     17367\n",
       "5      9493\n",
       "4      2747\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predict_true = pd.read_parquet(\"ground_truth.parquet\")[\"Cover_Type\"]\n",
    "predict_true.value_counts()\n",
    "# df_train = pd.read_csv(\"train.csv\")\n",
    "# df_train.Cover_Type.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48759922342395684,\n",
       " 0.36460520608868663,\n",
       " 0.06153745533655071,\n",
       " 0.03530047572167184,\n",
       " 0.02989094889606411,\n",
       " 0.016338733107061472,\n",
       " 0.004727957426008413]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [283301,211840,35754,20510,17367,9493,2747]\n",
    "b = [i/sum(a) for i in a]\n",
    "# print(a[0]/a[1])\n",
    "# print(80000/60000)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: if categories is an array, it has to be of shape (n_features,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m df_train1\n\u001b[1;32m     11\u001b[0m enc \u001b[38;5;241m=\u001b[39m OneHotEncoder(categories\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mELU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstone\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m df_train1 \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mfit_transform(df_train1)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    279\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1061\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1047\u001b[0m             (\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1057\u001b[0m         )\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    Fit OneHotEncoder to X.\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m        Fitted encoder.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    976\u001b[0m         X,\n\u001b[1;32m    977\u001b[0m         handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown,\n\u001b[1;32m    978\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_drop_idx()\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:85\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories) \u001b[38;5;241m!=\u001b[39m n_features:\n\u001b[0;32m---> 85\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch: if categories is an array,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m it has to be of shape (n_features,).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     91\u001b[0m category_counts \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: if categories is an array, it has to be of shape (n_features,)."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ELU_new = {k:v['ELU']%100 for k, v in ST.items()}\n",
    "df_train1['ELU'] = df_train1['ST_concat'].map(ELU_new)\n",
    "family_new = {k:v['family'] for k, v in ST.items()}\n",
    "df_train1['family'] = df_train1['ST_concat'].map(family_new)\n",
    "stone_new = {k:v['stone'] for k, v in ST.items()}\n",
    "df_train1['stone'] = df_train1['ST_concat'].map(stone_new)\n",
    "\n",
    "df_train1\n",
    "enc = OneHotEncoder(categories=['ELU', \"family\", \"stone\"])\n",
    "df_train1 = enc.fit_transform(df_train1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
